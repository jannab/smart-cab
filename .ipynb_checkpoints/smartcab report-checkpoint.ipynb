{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Smartcab to Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the project “Train a Smartcab to Drive”, a smartcab operating in an idealized grid-like city is given. There are traffic lights at each intersection and other cars present. The smartcab gets a reward for obeying traffic rules and a penalty for not obeying traffic rules or causing an accident. Goal of this project is to implement a learning agent for the smartcab that should learn an optimal policy for driving on city roads, obeying traffic rules correctly, and trying to reach the destination within a goal time based on the rewards and penalties it gets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Implement a basic driving agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, I let the smart cab take a random action out of the possibilities of:\n",
    "\n",
    "- doing nothing (state ‘None’)\n",
    "- driving forward (state ‘forward’)\n",
    "- turning left (state ‘left’)\n",
    "- turning right (state ‘right’)\n",
    "\n",
    "In this step, the smartcab does not learn from the results of it’s actions and has unlimited time to reach the goal.\n",
    "\n",
    "I put the printed output of my test run into `'output_first_text.txt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (\"output_first_text.txt\", \"r\") as myfile:\n",
    "    output_1 = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count reached 62\n",
      "Count aborted 39\n"
     ]
    }
   ],
   "source": [
    "count_reached = output_1.count('Primary agent has reached destination!')\n",
    "count_aborted = output_1.count('Primary agent hit hard time limit (-100)! Trial aborted.')\n",
    "print \"Count reached \" + str(count_reached)\n",
    "print \"Count aborted \" + str(count_aborted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts of destination reached and aborted trials add up to 101, which makes sense looking at the output file. The trials start with a trial number 0 and end with a trial number 100.\n",
    "\n",
    "This shows, that our smartcab is in about 60% of the trials able to reach the destination in the given time plus 100 extra steps. In 40% of the time even the 100 extra steps are not enough to let the smartcab reach it's destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Identify and update state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I modeled states explicity for our given traffic rules. These states could easily be changed to work in an environment where we don't know which traffic light color is the one to go or to an environment where we might drive on the other side. In this case, the number of states would increase accordingly (for example I would look at more inputs when the traffic light is red).\n",
    "\n",
    "Reducing the states I had in mind to keep the states as simple and understandable as possible. Each of my chosen states uses only the inputs needed to let us know if our smartcab should stop or go. With a smartcab heading forward, a red traffic light is enough to know it should stop, we don't have to know if there is another car oncoming, on the left or on the right.\n",
    "\n",
    "I chose to look at the following states:\n",
    "- forward, red light\n",
    "- forward, green light\n",
    "- turn right, green light\n",
    "- turn right, red light, someone left\n",
    "- turn right, red light, no one left\n",
    "- turn left, red light\n",
    "- turn left, green light, someone oncoming\n",
    "- turn left, green light, no one oncoming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Implement Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step I implemented the q-learning algorithm with a learning rate of 0.5 and a discount factor of 0.5. The next action is always chosen based on the best estemate based on the current state.\n",
    "\n",
    "I put the printed output of my test run into `'output_first_text.txt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (\"output_second_text.txt\", \"r\") as myfile:\n",
    "    output_1 = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count reached 0\n",
      "Count aborted 100\n"
     ]
    }
   ],
   "source": [
    "count_reached = output_1.count('Primary agent has reached destination!')\n",
    "count_aborted = output_1.count('Primary agent hit hard time limit (-100)! Trial aborted.')\n",
    "print \"Count reached \" + str(count_reached)\n",
    "print \"Count aborted \" + str(count_aborted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the smartcab does not reach it's destination in a single trial, even though it has the 100 extra steps. It's obvious in the visualization that the smartcab sticks to actions it took before, rarely trying a new action. I suspect that especially the discount factor could play a role here.\n",
    "\n",
    "Let's try to fix this by tweaking the values for the learning rate and discount factor first."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
